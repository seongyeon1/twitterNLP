{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing_final",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHLleRxmTUlPkWKvubgPVZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seongyeon1/twitterNLP/blob/main/preprocessing_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
        "from keras import utils\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# Word2vec\n",
        "import gensim\n",
        "\n",
        "# Utility\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "import logging\n",
        "import time\n",
        "import pickle\n",
        "import itertools\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "metadata": {
        "id": "0IT7rf2bTKCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb90c3cb-4b20-45c5-888d-e9cfecb178d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version:  2.8.2\n",
            "Eager mode:  True\n",
            "Hub version:  0.12.0\n",
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "Edj4FNybjry1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a2d064-c434-43b9-de6a-6a4ca0612a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLEs5Q6HS3XT",
        "outputId": "9058a130-c63c-4850-a3a0-44d416191029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_IN_PATH = '/content/drive/MyDrive/ColabNotebooks/datasets/sentiments/'"
      ],
      "metadata": {
        "id": "uOzQ7EyOS45W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(DATA_IN_PATH + 'train.csv')\n",
        "test_data = pd.read_csv(DATA_IN_PATH + 'test.csv')\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EfqZDTvlS41j",
        "outputId": "ed707140-fd89-4d1b-93fb-ca7c62356c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
              "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
              "2   3      0  We love this! Would you go? #talk #makememorie...\n",
              "3   4      0  I'm wired I know I'm George I was made that wa...\n",
              "4   5      1  What amazing service! Apple won't even talk to..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51c2ca18-1d31-4bf8-996e-28d9b613a6c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>What amazing service! Apple won't even talk to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51c2ca18-1d31-4bf8-996e-28d9b613a6c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51c2ca18-1d31-4bf8-996e-28d9b613a6c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51c2ca18-1d31-4bf8-996e-28d9b613a6c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([train_data, test_data])"
      ],
      "metadata": {
        "id": "TULl1IOlS4ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "!pip install ktrain\n",
        "!pip install wordninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2fM3nen5g7LK",
        "outputId": "d57079d9-2199-4313-c2b6-11adb6b8ce01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ktrain\n",
            "  Downloading ktrain-0.31.2.tar.gz (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 59.2 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.3.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.3)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 59.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n",
            "\u001b[K     |████████████████████████████████| 263 kB 68.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
            "Collecting syntok==1.3.3\n",
            "  Downloading syntok-1.3.3-py3-none-any.whl (22 kB)\n",
            "Collecting transformers==4.10.3\n",
            "  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 47.6 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 62.1 MB/s \n",
            "\u001b[?25hCollecting keras_bert>=0.86.0\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 66.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->ktrain) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->ktrain) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->ktrain) (3.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from syntok==1.3.3->ktrain) (2019.12.20)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 64.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.3->ktrain) (4.64.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 50.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 68.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.3->ktrain) (4.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.3->ktrain) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.3->ktrain) (4.2.0)\n",
            "Collecting keras-transformer==0.40.0\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "Collecting keras-pos-embd==0.13.0\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "Collecting keras-multi-head==0.29.0\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "Collecting keras-layer-normalization==0.16.0\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "Collecting keras-position-wise-feed-forward==0.8.0\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "Collecting keras-embed-sim==0.10.0\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "Collecting keras-self-attention==0.51.0\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.3->ktrain) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.3->ktrain) (7.1.2)\n",
            "Building wheels for collected packages: ktrain, keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, sacremoses\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.31.2-py3-none-any.whl size=25313063 sha256=99ba12e104383a3e138acaafc85ee18f2072fb81264d7c4b54fb9d56089ec376\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/b3/dd/512a01ea0b4f31d96163518b58361bb72d3bcb916d291052e7\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33517 sha256=8c68fc3654fa811251d8703480ffef67fdd365ddd89bc7de1285ea4880c3ee05\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/e8/45/842b3a39831261aef9154b907eacbc4ac99499a99ae829b06f\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12305 sha256=3cff625fc63a025b0462689cf44dc8dd836120e336e425582c20ccec369660ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/68/26/692ed21edd832833c3b0a0e21615bcacd99ca458b3f9ed571f\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3960 sha256=e9546bfe595e5a188ddbde6f5a20a3f2bf01f8e3d58575f8056ed6a29a3ccb8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/67/b5/d847588d075895281e1cf5590f819bd4cf076a554872268bd5\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4668 sha256=c8e0785ed10d6a4f5924f66c174fd05abe98019abe6db7aa57f0dacee4777fa2\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/5d/1c/2e619f594f69fbcf8bc20943b27d414871c409be053994813e\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14993 sha256=f7c3563221e3ea156deae507bd3d4263a2ea689f8f0968e9288ee0f504b83bb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/aa/3c/9d15d24005179dae08ff291ce99c754b296347817d076fd9fb\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6962 sha256=87961f8e49ff3e1685213c869e923e7e99363a554f1bf2518258376aa1489bea\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/c1/a0/dc44fcf68c857b7ff6be9a97e675e5adf51022eff1169b042f\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=594f4017dc32f9806d44c5770c23f36689756339f6a22b7da04497c95ed71061\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/75/6f/d42f6e051506f442daeba53ff1e2d21a5f20ef8c411610f2bb\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=c7b8de4156196c7e74feef31990171bd915cae31aec2174a956ca6d744ab2661\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=72e54d83e2e7fd64821335b291ba69421e3b217de55bba92b4e5915ff4b7c2ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=153674598d1e4e0e64f3d73946e48ab40cdf669f4ad98b9790b621cf972d8043\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built ktrain keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect sacremoses\n",
            "Installing collected packages: keras-self-attention, pyyaml, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, tokenizers, sacremoses, keras-transformer, huggingface-hub, whoosh, transformers, syntok, sentencepiece, scikit-learn, langdetect, keras-bert, cchardet, ktrain\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "Successfully installed cchardet-2.1.7 huggingface-hub-0.7.0 keras-bert-0.89.0 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 ktrain-0.31.2 langdetect-1.0.9 pyyaml-6.0 sacremoses-0.0.53 scikit-learn-0.24.2 sentencepiece-0.1.96 syntok-1.3.3 tokenizers-0.10.3 transformers-4.10.3 whoosh-2.7.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wordninja\n",
            "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
            "\u001b[K     |████████████████████████████████| 541 kB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordninja\n",
            "  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541551 sha256=af3832be9077e47b27876cf9098b4d1e87e589b66fb25467614d4bed4c7a3f5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/3f/eb/a2692e3d2b9deb1487b09ba4967dd6920bd5032bfd9ff7acfc\n",
            "Successfully built wordninja\n",
            "Installing collected packages: wordninja\n",
            "Successfully installed wordninja-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unidecode\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "import wordninja\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "cxvwccHig3FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전처리"
      ],
      "metadata": {
        "id": "CazWLCNvE2a1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df[:7920]\n",
        "df_test = df[7920:]"
      ],
      "metadata": {
        "id": "GNUf9CaQu9gZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WORD2VEC \n",
        "W2V_SIZE = 300\n",
        "W2V_WINDOW = 7\n",
        "W2V_EPOCH = 32\n",
        "W2V_MIN_COUNT = 10"
      ],
      "metadata": {
        "id": "Eu94K0kAi4u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 불용어 처리"
      ],
      "metadata": {
        "id": "Cc-qo9OHFXL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "stop_words_list = ['no', 'nor', 'not', 'don', \"don't\", 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\",\n",
        "                   \"hadn't\", 'hasn', \"hasn't\", \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn',\n",
        "                   \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "\n",
        "for i in stop_words_list:\n",
        "  stop_words.remove((i))\n",
        "\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXUWn7XJi5B3",
        "outputId": "f0edec04-22c7-4e68-b3dd-79941af70301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'such', 'if', 'those', 'through', 'its', 'our', 'does', 'this', 'him', 'did', 'now', 'we', 'above', 'just', 'after', 'of', 'against', 'on', 'myself', 'having', 'hers', 'some', 'ain', 'once', 'between', 'own', 'ourselves', 'who', 'all', 've', 'am', 'because', 'their', 'to', 'a', 'hadn', 'from', 'yourselves', 'when', 'ours', 'other', 'these', 'they', 'can', 'in', 'o', 'is', 'again', 'she', 'have', 'it', 'that', 'then', 'why', \"that'll\", 'more', 'how', 'were', 'or', 'both', 'doing', 'll', 'my', 'as', 'off', 'for', 'too', 's', 'below', 'was', 'itself', 'by', 'with', \"it's\", 'be', 'but', 'do', 'himself', 'under', 'what', 'had', 'which', 'most', 'are', 'and', 't', \"she's\", 'y', 'into', 'me', 'theirs', 'whom', 'down', 'd', 'where', 'he', 'his', 'yours', 'here', 'i', 'so', 'your', 'during', 'while', 'each', 'yourself', \"you'd\", 'further', 'at', 'until', 'ma', 'the', 'before', 'few', 'being', 'you', 'themselves', \"you've\", 'an', 'only', 'there', 'them', 'very', 'should', \"should've\", 'will', 'has', 'about', 'over', 'haven', 'out', 'same', 'than', 'any', \"you'll\", 'herself', 'm', 'up', 're', 'been', 'her', \"you're\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(text, stem=False):\n",
        "\n",
        "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
        "    text = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\)|\\^\\^)', 'good', text)\n",
        "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
        "    text = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', 'laugh', text)\n",
        "    # Sad -- :-(, : (, :(, ):, )-:\n",
        "    text = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', 'bad', text)\n",
        "    # Cry -- :,(, :'(, :\"(\n",
        "    text = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', 'sad', text)\n",
        "\n",
        "    \n",
        "    # lower-case all characters\n",
        "    text=text.lower()\n",
        "    \n",
        "    # remove twitter handles\n",
        "    text= re.sub(r'@\\S+', '',text) \n",
        "    \n",
        "    # remove urls\n",
        "    text= re.sub(r'http\\S+', '',text) \n",
        "    text= re.sub(r'pic.\\S+', '',text)\n",
        "      \n",
        "    # replace unidecode characters\n",
        "    text=unidecode.unidecode(text)\n",
        "      \n",
        "    # regex only keeps characters\n",
        "    text= re.sub(r\"[^A-Za-z0-9]+\", ' ',text)\n",
        "    \n",
        "    # keep words with length>1 only\n",
        "    text=re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text+' ') \n",
        "\n",
        "    # split words like 'whatisthis' to 'what is this'\n",
        "    def preprocess_wordninja(sentence):      \n",
        "        def split_words(x):\n",
        "            x=wordninja.split(x)\n",
        "            x= [word for word in x if len(word)>1]\n",
        "            return x\n",
        "        new_sentence=[ ' '.join(split_words(word)) for word in sentence.split() ]\n",
        "        return ' '.join(new_sentence)\n",
        "    \n",
        "    text=preprocess_wordninja(text)\n",
        " \n",
        "    # regex removes repeated spaces, strip removes leading and trailing spaces\n",
        "    text= re.sub(\"\\s[\\s]+\", \" \",text).strip()  \n",
        "    tokens = []\n",
        "    for token in text.split():\n",
        "        if token not in stop_words:\n",
        "          if stem:\n",
        "              tokens.append(stemmer.stem(token))\n",
        "          else:\n",
        "              tokens.append(token)\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "NLi0MjVqWezK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df.tweet = df.tweet.apply(lambda x: clean_tweet(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxCi5lTK6jtE",
        "outputId": "9683de97-9068-4ba5-f967-c868284d17bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.02 s, sys: 14.6 ms, total: 4.04 s\n",
            "Wall time: 4.03 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "bv9Wh7BfLhy-",
        "outputId": "94c1e3e0-4e94-4487-cabf-6a11a208d0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  label                                              tweet\n",
              "0        1    0.0  fingerprint pregnancy test android apps beauti...\n",
              "1        2    0.0  finally trans paran silicon case good thanks u...\n",
              "2        3    0.0  love would go talk make memories unplug relax ...\n",
              "3        4    0.0  i'm wired know i'm george made way iphone cute...\n",
              "4        5    1.0  amazing service apple won't even talk question...\n",
              "...    ...    ...                                                ...\n",
              "1948  9869    NaN  samsung galaxy note explodes burns year old th...\n",
              "1949  9870    NaN  available hood ie check iphone case music disc...\n",
              "1950  9871    NaN  goes crack right across screen could actually ...\n",
              "1951  9872    NaN         said adobe big time may well include apple\n",
              "1952  9873    NaN  finally got father samsung galaxy gift father ...\n",
              "\n",
              "[9873 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b84b4b24-2c42-4911-8d13-25458b70d2c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>fingerprint pregnancy test android apps beauti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>finally trans paran silicon case good thanks u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>love would go talk make memories unplug relax ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>i'm wired know i'm george made way iphone cute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>amazing service apple won't even talk question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1948</th>\n",
              "      <td>9869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>samsung galaxy note explodes burns year old th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1949</th>\n",
              "      <td>9870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>available hood ie check iphone case music disc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1950</th>\n",
              "      <td>9871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>goes crack right across screen could actually ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1951</th>\n",
              "      <td>9872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>said adobe big time may well include apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1952</th>\n",
              "      <td>9873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>finally got father samsung galaxy gift father ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9873 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b84b4b24-2c42-4911-8d13-25458b70d2c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b84b4b24-2c42-4911-8d13-25458b70d2c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b84b4b24-2c42-4911-8d13-25458b70d2c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}